{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Dataset\n",
    "\n",
    "Source: https://docs.ragas.io/en/latest/getstarted/rag_testset_generation/#choose-your-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragas\n",
    "%pip install unstructured\n",
    "%pip install unstructured[pdf]\n",
    "%pip install unstructured[docx]\n",
    "%pip install 'langchain-openai>=0.2.1,<0.3.0'\n",
    "%pip install 'tiktoken>=0.7.0,<0.8.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure configurations\n",
    "\n",
    "You always need to run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "azure_search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "azure_search_service_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "azure_search_service_index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "embedding_endpoint =  os.getenv(\"EMBEDDING_ENDPOINT_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n",
    "\n",
    "Note: I had an error loading to files first time so I had to run this in the github codespaces terminal:\n",
    "- sudo apt-get update\n",
    "- sudo apt-get install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"../data/hikingproducts/dataset\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    validate_base_url=False,\n",
    "    api_key=azure_openai_key\n",
    "))\n",
    "\n",
    "# init the embeddings for answer_relevancy, answer_correctness and answer_similarity\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(AzureOpenAIEmbeddings(\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    model=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.94it/s]                                             \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:10<00:00,  3.62s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [00:04<00:00,  2.78it/s]\n"
     ]
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save just the query and ground truth to a JSONL file for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create DataFrame\n",
    "df = dataset.to_pandas()\n",
    "\n",
    "# Create a new DataFrame for EvalCollection\n",
    "eval_collection = pd.DataFrame(columns=['query', 'response', 'context', 'ground_truth'])\n",
    "\n",
    "# Populate the new DataFrame\n",
    "eval_collection['query'] = df['user_input']\n",
    "eval_collection['ground_truth'] = df['reference']\n",
    "eval_collection['response'] = ''\n",
    "eval_collection['context'] = ''\n",
    "\n",
    "# Save the DataFrame as a JSONL file\n",
    "eval_collection.to_json('../data/hikingproducts/evaluation/hikingproductseval.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Response and Context from the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalCollection has been saved to hikingproductsevalfinal.jsonl\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_api_version,\n",
    ")\n",
    "\n",
    "# Iterate through the DataFrame and generate responses and their contexts\n",
    "for index, row in eval_collection.iterrows():\n",
    "    # User Query\n",
    "    query = row['query']  \n",
    "\n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant that helps people find information.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Message structure for the chat prompt\n",
    "    messages = chat_prompt\n",
    "\n",
    "    # Generate response using the Azure OpenAI client\n",
    "    completion = client.chat.completions.create(\n",
    "        model=azure_openai_deployment,\n",
    "        messages=messages,\n",
    "        max_tokens=800,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "        extra_body={\n",
    "        \"data_sources\": [{\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": azure_search_service_endpoint,\n",
    "                \"index_name\": azure_search_service_index_name,\n",
    "                \"semantic_configuration\": \"hikingproductsindex01-semantic-configuration\",\n",
    "                \"query_type\": \"vector_semantic_hybrid\",\n",
    "                \"fields_mapping\": {\n",
    "                \"content_fields_separator\": \"\\n\",\n",
    "                \"content_fields\": [\n",
    "                    \"chunk\"\n",
    "                ],\n",
    "                \"filepath_field\": \"title\",\n",
    "                \"title_field\": \"chunk_id\",\n",
    "                \"url_field\": None,\n",
    "                \"vector_fields\": [\n",
    "                    \"text_vector\"\n",
    "                ]\n",
    "                },\n",
    "                \"in_scope\": True,\n",
    "                \"filter\": None,\n",
    "                \"strictness\": 3,\n",
    "                \"top_n_documents\": 3,\n",
    "                \"authentication\": {\n",
    "                \"type\": \"api_key\",\n",
    "                \"key\": azure_search_service_admin_key\n",
    "                },\n",
    "                \"embedding_dependency\": {\n",
    "                \"type\": \"endpoint\",\n",
    "                \"endpoint\": embedding_endpoint,\n",
    "                \"authentication\": {\n",
    "                    \"type\": \"api_key\",\n",
    "                    \"key\": azure_openai_key\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "            }]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    citations_combined = \"\"\n",
    "    response_json = json.loads(completion.to_json())\n",
    "    citations = response_json['choices'][0]['message']['context']['citations']\n",
    "    citations_combined = \"\\n=============\\n\".join(citation['content'] for citation in citations)\n",
    "\n",
    "    # Update the response and context in the DataFrame\n",
    "    eval_collection.at[index, 'response'] = completion.choices[0].message.content\n",
    "    eval_collection.at[index, 'context'] = citations_combined\n",
    "    \n",
    "# Save the updated DataFrame as a JSONL file\n",
    "eval_collection.to_json('../data/hikingproducts/evaluation/hikingproductsevalfinal.jsonl', orient='records', lines=True)\n",
    "\n",
    "# Print success message\n",
    "print(\"EvalCollection has been saved to hikingproductsevalfinal.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
