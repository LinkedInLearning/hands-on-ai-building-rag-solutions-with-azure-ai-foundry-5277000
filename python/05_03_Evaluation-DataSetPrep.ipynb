{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Evaluation Dataset\n",
    "\n",
    "Source: https://docs.ragas.io/en/latest/getstarted/rag_testset_generation/#choose-your-llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ragas\n",
    "%pip install unstructured\n",
    "%pip install unstructured[pdf]\n",
    "%pip install unstructured[docx]\n",
    "%pip install 'langchain-openai>=0.2.1,<0.3.0'\n",
    "%pip install 'tiktoken>=0.7.0,<0.8.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Azure configurations\n",
    "\n",
    "You always need to run this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "azure_openai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "azure_openai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_openai_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "azure_openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT\")\n",
    "azure_openai_api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "azure_search_service_endpoint = os.getenv(\"AZURE_SEARCH_SERVICE_ENDPOINT\")\n",
    "azure_search_service_admin_key = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "azure_search_service_index_name = os.getenv(\"AZURE_SEARCH_INDEX_NAME\")\n",
    "azure_search_service_semantic_config = os.getenv(\"AZURE_SEARCH_SEMANTIC_CONFIG\")\n",
    "embedding_endpoint =  os.getenv(\"EMBEDDING_ENDPOINT_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Documents\n",
    "\n",
    "Note: I had an error loading to files first time so I had to run this in the github codespaces terminal:\n",
    "- sudo apt-get update\n",
    "- sudo apt-get install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vscode/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "path = \"../data/hikingproducts/dataset\"\n",
    "loader = DirectoryLoader(path, glob=\"**/*.pdf\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "\n",
    "generator_llm = LangchainLLMWrapper(AzureChatOpenAI(\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_deployment,\n",
    "    model=azure_openai_deployment,\n",
    "    validate_base_url=False,\n",
    "    api_key=azure_openai_key\n",
    "))\n",
    "\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(AzureOpenAIEmbeddings(\n",
    "    openai_api_version=azure_openai_api_version,\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    azure_deployment=azure_openai_embeddings_deployment,\n",
    "    model=azure_openai_embeddings_deployment,\n",
    "    api_key=azure_openai_key\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|██████████| 3/3 [00:01<00:00,  2.68it/s]                                             \n",
      "Generating Scenarios: 100%|██████████| 3/3 [00:12<00:00,  4.15s/it]\n",
      "Generating Samples: 100%|██████████| 12/12 [00:03<00:00,  3.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As someone who values reliable gear for both h...</td>\n",
       "      <td>[Summit Breeze Jacket User Manual ### Introduc...</td>\n",
       "      <td>The 1-year limited warranty for the Summit Bre...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What are the features and benefits of the Summ...</td>\n",
       "      <td>[# Information about product item_number: 3 Su...</td>\n",
       "      <td>The Summit Breeze Jacket in black offers a lig...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I am a Gold memebr and I want to kno if I can ...</td>\n",
       "      <td>[defective product. If the exact product is no...</td>\n",
       "      <td>If you have Gold membership status, you can re...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What features make the MountainDream Sleeping ...</td>\n",
       "      <td>[# Information about product item_number: 14 M...</td>\n",
       "      <td>The MountainDream Sleeping Bag is suitable for...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do the care and maintenance guidelines for...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nSummit Breeze Jacket User Manual #...</td>\n",
       "      <td>The care and maintenance guidelines for the Su...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0  As someone who values reliable gear for both h...   \n",
       "1  What are the features and benefits of the Summ...   \n",
       "2  I am a Gold memebr and I want to kno if I can ...   \n",
       "3  What features make the MountainDream Sleeping ...   \n",
       "4  How do the care and maintenance guidelines for...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [Summit Breeze Jacket User Manual ### Introduc...   \n",
       "1  [# Information about product item_number: 3 Su...   \n",
       "2  [defective product. If the exact product is no...   \n",
       "3  [# Information about product item_number: 14 M...   \n",
       "4  [<1-hop>\\n\\nSummit Breeze Jacket User Manual #...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  The 1-year limited warranty for the Summit Bre...   \n",
       "1  The Summit Breeze Jacket in black offers a lig...   \n",
       "2  If you have Gold membership status, you can re...   \n",
       "3  The MountainDream Sleeping Bag is suitable for...   \n",
       "4  The care and maintenance guidelines for the Su...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas.testset import TestsetGenerator\n",
    "import pandas as pd\n",
    "\n",
    "generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n",
    "dataset = generator.generate_with_langchain_docs(docs, testset_size=10)\n",
    "\n",
    "# Create DataFrame\n",
    "df = dataset.to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save just the query and ground truth to a JSONL file for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for EvalCollection\n",
    "eval_collection = pd.DataFrame(columns=['query', 'response', 'context', 'ground_truth'])\n",
    "\n",
    "# Populate the new DataFrame\n",
    "eval_collection['query'] = df['user_input']\n",
    "eval_collection['ground_truth'] = df['reference']\n",
    "eval_collection['response'] = ''\n",
    "eval_collection['context'] = ''\n",
    "\n",
    "# Save the DataFrame as a JSONL file\n",
    "eval_collection.to_json('../data/hikingproducts/evaluation/hikingproductseval.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Response and Context from the Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EvalCollection has been saved to hikingproductsevalfinal.jsonl\n"
     ]
    }
   ],
   "source": [
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "# Initialize Azure OpenAI client with key-based authentication\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint=azure_openai_endpoint,\n",
    "    api_key=azure_openai_key,\n",
    "    api_version=azure_openai_api_version,\n",
    ")\n",
    "\n",
    "# Iterate through the DataFrame and generate responses and their contexts\n",
    "for index, row in eval_collection.iterrows():\n",
    "    # User Query\n",
    "    query = row['query']  \n",
    "\n",
    "    chat_prompt = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI assistant that helps people find information.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": query\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Message structure for the chat prompt\n",
    "    messages = chat_prompt\n",
    "\n",
    "    # Generate response using the Azure OpenAI client\n",
    "    completion = client.chat.completions.create(\n",
    "        model=azure_openai_deployment,\n",
    "        messages=messages,\n",
    "        max_tokens=800,\n",
    "        temperature=1,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        stop=None,\n",
    "        stream=False,\n",
    "        extra_body={\n",
    "        \"data_sources\": [{\n",
    "            \"type\": \"azure_search\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": azure_search_service_endpoint,\n",
    "                \"index_name\": azure_search_service_index_name,\n",
    "                \"semantic_configuration\": azure_search_service_semantic_config,\n",
    "                \"query_type\": \"vector_semantic_hybrid\",\n",
    "                \"fields_mapping\": {\n",
    "                \"content_fields_separator\": \"\\n\",\n",
    "                \"content_fields\": [\n",
    "                    \"chunk\"\n",
    "                ],\n",
    "                \"filepath_field\": \"title\",\n",
    "                \"title_field\": \"chunk_id\",\n",
    "                \"url_field\": None,\n",
    "                \"vector_fields\": [\n",
    "                    \"text_vector\"\n",
    "                ]\n",
    "                },\n",
    "                \"in_scope\": True,\n",
    "                \"filter\": None,\n",
    "                \"strictness\": 3,\n",
    "                \"top_n_documents\": 3,\n",
    "                \"authentication\": {\n",
    "                \"type\": \"api_key\",\n",
    "                \"key\": azure_search_service_admin_key\n",
    "                },\n",
    "                \"embedding_dependency\": {\n",
    "                \"type\": \"endpoint\",\n",
    "                \"endpoint\": embedding_endpoint,\n",
    "                \"authentication\": {\n",
    "                    \"type\": \"api_key\",\n",
    "                    \"key\": azure_openai_key\n",
    "                }\n",
    "                }\n",
    "            }\n",
    "            }]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    citations_combined = \"\"\n",
    "    response_json = json.loads(completion.to_json())\n",
    "    citations = response_json['choices'][0]['message']['context']['citations']\n",
    "    citations_combined = \"\\n=============\\n\".join(citation['content'] for citation in citations)\n",
    "\n",
    "    # Update the response and context in the DataFrame\n",
    "    eval_collection.at[index, 'response'] = completion.choices[0].message.content\n",
    "    eval_collection.at[index, 'context'] = citations_combined\n",
    "    \n",
    "# Save the updated DataFrame as a JSONL file\n",
    "eval_collection.to_json('../data/hikingproducts/evaluation/hikingproductsevalfinal.jsonl', orient='records', lines=True)\n",
    "\n",
    "# Print success message\n",
    "print(\"EvalCollection has been saved to hikingproductsevalfinal.jsonl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
